{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "Ce notebook utilise la méthode de gradient boosting afin de réaliser des prédictions. La bibliothèque XGBoost a été utilisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16323 entries, 0 to 16322\n",
      "Data columns (total 23 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   id                      16323 non-null  int64  \n",
      " 1   date                    16323 non-null  object \n",
      " 2   prix                    16323 non-null  int64  \n",
      " 3   nb_chambres             16323 non-null  int64  \n",
      " 4   nb_sdb                  16323 non-null  float64\n",
      " 5   m2_interieur            16323 non-null  float64\n",
      " 6   m2_jardin               16323 non-null  float64\n",
      " 7   m2_etage                16323 non-null  float64\n",
      " 8   m2_soussol              16323 non-null  float64\n",
      " 9   nb_etages               16323 non-null  float64\n",
      " 10  vue_mer                 16323 non-null  int64  \n",
      " 11  vue_note                16323 non-null  int64  \n",
      " 12  etat_note               16323 non-null  int64  \n",
      " 13  design_note             16323 non-null  int64  \n",
      " 14  annee_construction      16323 non-null  int64  \n",
      " 15  annee_renovation        16323 non-null  int64  \n",
      " 16  m2_interieur_15voisins  16323 non-null  float64\n",
      " 17  m2_jardin_15voisins     16323 non-null  float64\n",
      " 18  zipcode                 16323 non-null  int64  \n",
      " 19  lat                     16323 non-null  float64\n",
      " 20  long                    16323 non-null  float64\n",
      " 21  cos_month               16323 non-null  float64\n",
      " 22  day_count               16323 non-null  int64  \n",
      "dtypes: float64(11), int64(11), object(1)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "doc = '_cleaned_w_outlier_feat.csv'\n",
    "df = pd.read_csv('Data/train'+doc)\n",
    "df = df.dropna()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "features = ['nb_chambres', 'm2_etage', 'nb_sdb', 'm2_interieur', 'm2_soussol','m2_jardin', 'nb_etages', 'vue_mer', 'vue_note', 'etat_note', 'design_note', 'annee_construction', 'annee_renovation', 'm2_interieur_15voisins', 'm2_jardin_15voisins', 'zipcode', 'lat', 'long', 'cos_month', 'day_count']\n",
    "X = df[features]\n",
    "print(len(features))\n",
    "y = df['prix']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'tree_method': 'hist',\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'max_depth': 5,\n",
    "    'eta': 0.3,\n",
    "    'subsample':0.95,\n",
    "    'learning_rate':0.01\n",
    "}\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 932258050.6415\n",
      "R-squared Score: 0.9904846785014021\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(dtrain)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "r2 = r2_score(y_train, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Data/test_cleaned_feat.csv')\n",
    "df_test = df_test.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.dropna()\n",
    "X_df_test = df_test[features]\n",
    "X_df_test = xgb.DMatrix(X_df_test)\n",
    "y_pred = model.predict(X_df_test)\n",
    "#create the csv result.csv that concatenate the id and the predicted price\n",
    "y_pred = pd.Series(y_pred, name='prix')  # name is optional, just for clarity\n",
    "result = pd.concat([df_test['id'], y_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns = ['id', 'prix']\n",
    "result.to_csv('Data/result_XGB'+doc+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ISDO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
